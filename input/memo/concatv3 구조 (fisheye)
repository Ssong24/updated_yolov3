layer                                     name  gradient   parameters                shape         mu      sigma
    0                          0.Conv2d.weight      True          864        [32, 3, 3, 3]  -8.67e-05      0.112
    1                     0.BatchNorm2d.weight      True           32                 [32]          1          0
    2                       0.BatchNorm2d.bias      True           32                 [32]          0          0
    3                          1.Conv2d.weight      True        18432       [64, 32, 3, 3]   0.000242      0.034
    4                     1.BatchNorm2d.weight      True           64                 [64]          1          0
    5                       1.BatchNorm2d.bias      True           64                 [64]          0          0
    6                          2.Conv2d.weight      True         2048       [32, 64, 1, 1]   0.000321      0.072
    7                     2.BatchNorm2d.weight      True           32                 [32]          1          0
    8                       2.BatchNorm2d.bias      True           32                 [32]          0          0
    9                          3.Conv2d.weight      True        18432       [64, 32, 3, 3]   0.000188     0.0339
   10                     3.BatchNorm2d.weight      True           64                 [64]          1          0
   11                       3.BatchNorm2d.bias      True           64                 [64]          0          0
   12                          5.Conv2d.weight      True        73728      [128, 64, 3, 3]  -2.89e-05     0.0241
   13                     5.BatchNorm2d.weight      True          128                [128]          1          0
   14                       5.BatchNorm2d.bias      True          128                [128]          0          0
   15                          6.Conv2d.weight      True         8192      [64, 128, 1, 1]   0.000717     0.0513
   16                     6.BatchNorm2d.weight      True           64                 [64]          1          0
   17                       6.BatchNorm2d.bias      True           64                 [64]          0          0
   18                          7.Conv2d.weight      True        73728      [128, 64, 3, 3]   0.000112     0.0241
   19                     7.BatchNorm2d.weight      True          128                [128]          1          0
   20                       7.BatchNorm2d.bias      True          128                [128]          0          0
   21                          9.Conv2d.weight      True         8192      [64, 128, 1, 1]  -0.000266      0.051
   22                     9.BatchNorm2d.weight      True           64                 [64]          1          0
   23                       9.BatchNorm2d.bias      True           64                 [64]          0          0
   24                         10.Conv2d.weight      True        73728      [128, 64, 3, 3]    -0.0002     0.0241
   25                    10.BatchNorm2d.weight      True          128                [128]          1          0
   26                      10.BatchNorm2d.bias      True          128                [128]          0          0
   27                         12.Conv2d.weight      True       294912     [256, 128, 3, 3]   4.95e-05      0.017
   28                    12.BatchNorm2d.weight      True          256                [256]          1          0
   29                      12.BatchNorm2d.bias      True          256                [256]          0          0
   30                         13.Conv2d.weight      True        32768     [128, 256, 1, 1]   -9.5e-05      0.036
   31                    13.BatchNorm2d.weight      True          128                [128]          1          0
   32                      13.BatchNorm2d.bias      True          128                [128]          0          0
   33                         14.Conv2d.weight      True       294912     [256, 128, 3, 3]  -2.46e-06      0.017
   34                    14.BatchNorm2d.weight      True          256                [256]          1          0
   35                      14.BatchNorm2d.bias      True          256                [256]          0          0
   36                         16.Conv2d.weight      True        32768     [128, 256, 1, 1]   0.000225     0.0359
   37                    16.BatchNorm2d.weight      True          128                [128]          1          0
   38                      16.BatchNorm2d.bias      True          128                [128]          0          0
   39                         17.Conv2d.weight      True       294912     [256, 128, 3, 3]  -5.76e-05      0.017
   40                    17.BatchNorm2d.weight      True          256                [256]          1          0
   41                      17.BatchNorm2d.bias      True          256                [256]          0          0
   42                         19.Conv2d.weight      True        32768     [128, 256, 1, 1]  -6.58e-05      0.036
   43                    19.BatchNorm2d.weight      True          128                [128]          1          0
   44                      19.BatchNorm2d.bias      True          128                [128]          0          0
   45                         20.Conv2d.weight      True       294912     [256, 128, 3, 3]  -1.72e-06      0.017
   46                    20.BatchNorm2d.weight      True          256                [256]          1          0
   47                      20.BatchNorm2d.bias      True          256                [256]          0          0
   48                         22.Conv2d.weight      True        32768     [128, 256, 1, 1]   0.000157      0.036
   49                    22.BatchNorm2d.weight      True          128                [128]          1          0
   50                      22.BatchNorm2d.bias      True          128                [128]          0          0
   51                         23.Conv2d.weight      True       294912     [256, 128, 3, 3]   2.92e-05      0.017
   52                    23.BatchNorm2d.weight      True          256                [256]          1          0
   53                      23.BatchNorm2d.bias      True          256                [256]          0          0
   54                         25.Conv2d.weight      True        32768     [128, 256, 1, 1]   0.000226     0.0361
   55                    25.BatchNorm2d.weight      True          128                [128]          1          0
   56                      25.BatchNorm2d.bias      True          128                [128]          0          0
   57                         26.Conv2d.weight      True       294912     [256, 128, 3, 3]   1.74e-05      0.017
   58                    26.BatchNorm2d.weight      True          256                [256]          1          0
   59                      26.BatchNorm2d.bias      True          256                [256]          0          0
   60                         28.Conv2d.weight      True        32768     [128, 256, 1, 1]   0.000182      0.036
   61                    28.BatchNorm2d.weight      True          128                [128]          1          0
   62                      28.BatchNorm2d.bias      True          128                [128]          0          0
   63                         29.Conv2d.weight      True       294912     [256, 128, 3, 3]   5.26e-07      0.017
   64                    29.BatchNorm2d.weight      True          256                [256]          1          0
   65                      29.BatchNorm2d.bias      True          256                [256]          0          0
   66                         31.Conv2d.weight      True        32768     [128, 256, 1, 1]  -0.000297     0.0361
   67                    31.BatchNorm2d.weight      True          128                [128]          1          0
   68                      31.BatchNorm2d.bias      True          128                [128]          0          0
   69                         32.Conv2d.weight      True       294912     [256, 128, 3, 3]   4.21e-05      0.017
   70                    32.BatchNorm2d.weight      True          256                [256]          1          0
   71                      32.BatchNorm2d.bias      True          256                [256]          0          0
   72                         34.Conv2d.weight      True        32768     [128, 256, 1, 1]   2.84e-05      0.036
   73                    34.BatchNorm2d.weight      True          128                [128]          1          0
   74                      34.BatchNorm2d.bias      True          128                [128]          0          0
   75                         35.Conv2d.weight      True       294912     [256, 128, 3, 3]  -4.58e-05      0.017
   76                    35.BatchNorm2d.weight      True          256                [256]          1          0
   77                      35.BatchNorm2d.bias      True          256                [256]          0          0
   78                         37.Conv2d.weight      True  1.17965e+06     [512, 256, 3, 3]   2.59e-06      0.012
   79                    37.BatchNorm2d.weight      True          512                [512]          1          0
   80                      37.BatchNorm2d.bias      True          512                [512]          0          0
   81                         38.Conv2d.weight      True       131072     [256, 512, 1, 1]  -2.42e-05     0.0255
   82                    38.BatchNorm2d.weight      True          256                [256]          1          0
   83                      38.BatchNorm2d.bias      True          256                [256]          0          0
   84                         39.Conv2d.weight      True  1.17965e+06     [512, 256, 3, 3]   6.23e-06      0.012
   85                    39.BatchNorm2d.weight      True          512                [512]          1          0
   86                      39.BatchNorm2d.bias      True          512                [512]          0          0
   87                         41.Conv2d.weight      True       131072     [256, 512, 1, 1]    3.8e-05     0.0255
   88                    41.BatchNorm2d.weight      True          256                [256]          1          0
   89                      41.BatchNorm2d.bias      True          256                [256]          0          0
   90                         42.Conv2d.weight      True  1.17965e+06     [512, 256, 3, 3]  -1.15e-05      0.012
   91                    42.BatchNorm2d.weight      True          512                [512]          1          0
   92                      42.BatchNorm2d.bias      True          512                [512]          0          0
   93                         44.Conv2d.weight      True       131072     [256, 512, 1, 1]   1.25e-07     0.0254
   94                    44.BatchNorm2d.weight      True          256                [256]          1          0
   95                      44.BatchNorm2d.bias      True          256                [256]          0          0
   96                         45.Conv2d.weight      True  1.17965e+06     [512, 256, 3, 3]  -1.02e-05      0.012
   97                    45.BatchNorm2d.weight      True          512                [512]          1          0
   98                      45.BatchNorm2d.bias      True          512                [512]          0          0
   99                         47.Conv2d.weight      True       131072     [256, 512, 1, 1]    0.00018     0.0255
  100                    47.BatchNorm2d.weight      True          256                [256]          1          0
  101                      47.BatchNorm2d.bias      True          256                [256]          0          0
  102                         48.Conv2d.weight      True  1.17965e+06     [512, 256, 3, 3]  -1.22e-05      0.012
  103                    48.BatchNorm2d.weight      True          512                [512]          1          0
  104                      48.BatchNorm2d.bias      True          512                [512]          0          0
  105                         50.Conv2d.weight      True       131072     [256, 512, 1, 1]  -2.25e-05     0.0255
  106                    50.BatchNorm2d.weight      True          256                [256]          1          0
  107                      50.BatchNorm2d.bias      True          256                [256]          0          0
  108                         51.Conv2d.weight      True  1.17965e+06     [512, 256, 3, 3]   6.82e-06      0.012
  109                    51.BatchNorm2d.weight      True          512                [512]          1          0
  110                      51.BatchNorm2d.bias      True          512                [512]          0          0
  111                         53.Conv2d.weight      True       131072     [256, 512, 1, 1]   -6.9e-05     0.0255
  112                    53.BatchNorm2d.weight      True          256                [256]          1          0
  113                      53.BatchNorm2d.bias      True          256                [256]          0          0
  114                         54.Conv2d.weight      True  1.17965e+06     [512, 256, 3, 3]   1.89e-06      0.012
  115                    54.BatchNorm2d.weight      True          512                [512]          1          0
  116                      54.BatchNorm2d.bias      True          512                [512]          0          0
  117                         56.Conv2d.weight      True       131072     [256, 512, 1, 1]    0.00015     0.0255
  118                    56.BatchNorm2d.weight      True          256                [256]          1          0
  119                      56.BatchNorm2d.bias      True          256                [256]          0          0
  120                         57.Conv2d.weight      True  1.17965e+06     [512, 256, 3, 3]   2.61e-05      0.012
  121                    57.BatchNorm2d.weight      True          512                [512]          1          0
  122                      57.BatchNorm2d.bias      True          512                [512]          0          0
  123                         59.Conv2d.weight      True       131072     [256, 512, 1, 1]  -0.000128     0.0256
  124                    59.BatchNorm2d.weight      True          256                [256]          1          0
  125                      59.BatchNorm2d.bias      True          256                [256]          0          0
  126                         60.Conv2d.weight      True  1.17965e+06     [512, 256, 3, 3]  -1.97e-06      0.012
  127                    60.BatchNorm2d.weight      True          512                [512]          1          0
  128                      60.BatchNorm2d.bias      True          512                [512]          0          0
  129                         62.Conv2d.weight      True  4.71859e+06    [1024, 512, 3, 3]   1.53e-06     0.0085
  130                    62.BatchNorm2d.weight      True         1024               [1024]          1          0
  131                      62.BatchNorm2d.bias      True         1024               [1024]          0          0
  132                         63.Conv2d.weight      True       524288    [512, 1024, 1, 1]  -1.84e-05     0.0181
  133                    63.BatchNorm2d.weight      True          512                [512]          1          0
  134                      63.BatchNorm2d.bias      True          512                [512]          0          0
  135                         64.Conv2d.weight      True  4.71859e+06    [1024, 512, 3, 3]   2.17e-07     0.0085
  136                    64.BatchNorm2d.weight      True         1024               [1024]          1          0
  137                      64.BatchNorm2d.bias      True         1024               [1024]          0          0
  138                         66.Conv2d.weight      True       524288    [512, 1024, 1, 1]   2.39e-05      0.018
  139                    66.BatchNorm2d.weight      True          512                [512]          1          0
  140                      66.BatchNorm2d.bias      True          512                [512]          0          0
  141                         67.Conv2d.weight      True  4.71859e+06    [1024, 512, 3, 3]  -1.41e-06    0.00851
  142                    67.BatchNorm2d.weight      True         1024               [1024]          1          0
  143                      67.BatchNorm2d.bias      True         1024               [1024]          0          0
  144                         69.Conv2d.weight      True       524288    [512, 1024, 1, 1]  -1.94e-05      0.018
  145                    69.BatchNorm2d.weight      True          512                [512]          1          0
  146                      69.BatchNorm2d.bias      True          512                [512]          0          0
  147                         70.Conv2d.weight      True  4.71859e+06    [1024, 512, 3, 3]   1.07e-06    0.00851
  148                    70.BatchNorm2d.weight      True         1024               [1024]          1          0
  149                      70.BatchNorm2d.bias      True         1024               [1024]          0          0
  150                         72.Conv2d.weight      True       524288    [512, 1024, 1, 1]   3.62e-05     0.0181
  151                    72.BatchNorm2d.weight      True          512                [512]          1          0
  152                      72.BatchNorm2d.bias      True          512                [512]          0          0
  153                         73.Conv2d.weight      True  4.71859e+06    [1024, 512, 3, 3]   4.51e-06     0.0085
  154                    73.BatchNorm2d.weight      True         1024               [1024]          1          0
  155                      73.BatchNorm2d.bias      True         1024               [1024]          0          0
  156                         75.Conv2d.weight      True       524288    [512, 1024, 1, 1]   2.73e-05      0.018
  157                    75.BatchNorm2d.weight      True          512                [512]          1          0
  158                      75.BatchNorm2d.bias      True          512                [512]          0          0
  159                         76.Conv2d.weight      True  4.71859e+06    [1024, 512, 3, 3]   2.64e-06     0.0085
  160                    76.BatchNorm2d.weight      True         1024               [1024]          1          0
  161                      76.BatchNorm2d.bias      True         1024               [1024]          0          0
  162                         77.Conv2d.weight      True       524288    [512, 1024, 1, 1]  -3.97e-05      0.018
  163                    77.BatchNorm2d.weight      True          512                [512]          1          0
  164                      77.BatchNorm2d.bias      True          512                [512]          0          0
  165                         84.Conv2d.weight      True  1.04858e+06    [512, 2048, 1, 1]  -1.05e-05     0.0128
  166                    84.BatchNorm2d.weight      True          512                [512]          1          0
  167                      84.BatchNorm2d.bias      True          512                [512]          0          0
  168                         85.Conv2d.weight      True  4.71859e+06    [1024, 512, 3, 3]   7.48e-07    0.00851
  169                    85.BatchNorm2d.weight      True         1024               [1024]          1          0
  170                      85.BatchNorm2d.bias      True         1024               [1024]          0          0
  171                         86.Conv2d.weight      True       524288    [512, 1024, 1, 1]    1.6e-05      0.018
  172                    86.BatchNorm2d.weight      True          512                [512]          1          0
  173                      86.BatchNorm2d.bias      True          512                [512]          0          0
  174                         88.Conv2d.weight      True  2.62144e+06   [1024, 2560, 1, 1]  -1.24e-05     0.0114
  175                    88.BatchNorm2d.weight      True         1024               [1024]          1          0
  176                      88.BatchNorm2d.bias      True         1024               [1024]          0          0
  177                         89.Conv2d.weight      True  9.43718e+06   [1024, 1024, 3, 3]   7.87e-07    0.00601
  178                    89.BatchNorm2d.weight      True         1024               [1024]          1          0
  179                      89.BatchNorm2d.bias      True         1024               [1024]          0          0
  180                         90.Conv2d.weight      True       524288    [512, 1024, 1, 1]  -2.14e-06      0.018
  181                    90.BatchNorm2d.weight      True          512                [512]          1          0
  182                      90.BatchNorm2d.bias      True          512                [512]          0          0
  183                         91.Conv2d.weight      True  4.71859e+06    [1024, 512, 3, 3]   3.92e-06     0.0085
  184                    91.BatchNorm2d.weight      True         1024               [1024]          1          0
  185                      91.BatchNorm2d.bias      True         1024               [1024]          0          0
  186                         92.Conv2d.weight      True        43008     [42, 1024, 1, 1]   0.000221      0.018
  187                           92.Conv2d.bias      True           42                 [42]      -1.99       1.37
  188                         95.Conv2d.weight      True       131072     [256, 512, 1, 1]  -5.12e-05     0.0255
  189                    95.BatchNorm2d.weight      True          256                [256]          1          0
  190                      95.BatchNorm2d.bias      True          256                [256]          0          0
  191                         98.Conv2d.weight      True       196608     [256, 768, 1, 1]   6.78e-06     0.0208
  192                    98.BatchNorm2d.weight      True          256                [256]          1          0
  193                      98.BatchNorm2d.bias      True          256                [256]          0          0
  194                         99.Conv2d.weight      True  1.17965e+06     [512, 256, 3, 3]    5.1e-06      0.012
  195                    99.BatchNorm2d.weight      True          512                [512]          1          0
  196                      99.BatchNorm2d.bias      True          512                [512]          0          0
  197                        100.Conv2d.weight      True       131072     [256, 512, 1, 1]  -6.28e-05     0.0255
  198                   100.BatchNorm2d.weight      True          256                [256]          1          0
  199                     100.BatchNorm2d.bias      True          256                [256]          0          0
  200                        102.Conv2d.weight      True        65536     [256, 256, 1, 1]    6.7e-05     0.0361
  201                   102.BatchNorm2d.weight      True          256                [256]          1          0
  202                     102.BatchNorm2d.bias      True          256                [256]          0          0
  203                        104.Conv2d.weight      True       131072     [256, 512, 1, 1]  -7.25e-05     0.0256
  204                   104.BatchNorm2d.weight      True          256                [256]          1          0
  205                     104.BatchNorm2d.bias      True          256                [256]          0          0
  206                        105.Conv2d.weight      True  1.17965e+06     [512, 256, 3, 3]   6.72e-06      0.012
  207                   105.BatchNorm2d.weight      True          512                [512]          1          0
  208                     105.BatchNorm2d.bias      True          512                [512]          0          0
  209                        106.Conv2d.weight      True       131072     [256, 512, 1, 1]   5.15e-05     0.0256
  210                   106.BatchNorm2d.weight      True          256                [256]          1          0
  211                     106.BatchNorm2d.bias      True          256                [256]          0          0
  212                        107.Conv2d.weight      True  1.17965e+06     [512, 256, 3, 3]  -1.72e-05      0.012
  213                   107.BatchNorm2d.weight      True          512                [512]          1          0
  214                     107.BatchNorm2d.bias      True          512                [512]          0          0
  215                        108.Conv2d.weight      True        21504      [42, 512, 1, 1]  -0.000175     0.0255
  216                          108.Conv2d.bias      True           42                 [42]      -1.98       1.36
  217                        111.Conv2d.weight      True        32768     [128, 256, 1, 1]   9.72e-05     0.0361
  218                   111.BatchNorm2d.weight      True          128                [128]          1          0
  219                     111.BatchNorm2d.bias      True          128                [128]          0          0
  220                        114.Conv2d.weight      True        49152     [128, 384, 1, 1]    0.00012     0.0296
  221                   114.BatchNorm2d.weight      True          128                [128]          1          0
  222                     114.BatchNorm2d.bias      True          128                [128]          0          0
  223                        115.Conv2d.weight      True       294912     [256, 128, 3, 3]   5.35e-05      0.017
  224                   115.BatchNorm2d.weight      True          256                [256]          1          0
  225                     115.BatchNorm2d.bias      True          256                [256]          0          0
  226                        116.Conv2d.weight      True        32768     [128, 256, 1, 1]   0.000189     0.0359
  227                   116.BatchNorm2d.weight      True          128                [128]          1          0
  228                     116.BatchNorm2d.bias      True          128                [128]          0          0
  229                        118.Conv2d.weight      True        32768     [256, 128, 1, 1]  -0.000232     0.0509
  230                   118.BatchNorm2d.weight      True          256                [256]          1          0
  231                     118.BatchNorm2d.bias      True          256                [256]          0          0
  232                        120.Conv2d.weight      True       884736     [256, 384, 3, 3]   6.29e-06    0.00982
  233                   120.BatchNorm2d.weight      True          256                [256]          1          0
  234                     120.BatchNorm2d.bias      True          256                [256]          0          0
  235                        121.Conv2d.weight      True        32768     [128, 256, 1, 1]   0.000186      0.036
  236                   121.BatchNorm2d.weight      True          128                [128]          1          0
  237                     121.BatchNorm2d.bias      True          128                [128]          0          0
  238                        122.Conv2d.weight      True       294912     [256, 128, 3, 3]   1.98e-05      0.017
  239                   122.BatchNorm2d.weight      True          256                [256]          1          0
  240                     122.BatchNorm2d.bias      True          256                [256]          0          0
  241                        123.Conv2d.weight      True       589824     [256, 256, 3, 3]    2.1e-05      0.012
  242                   123.BatchNorm2d.weight      True          256                [256]          1          0
  243                     123.BatchNorm2d.bias      True          256                [256]          0          0
  244                        124.Conv2d.weight      True        10752      [42, 256, 1, 1]   0.000217     0.0362
  245                          124.Conv2d.bias      True           42                 [42]      -1.98       1.37
Model Summary: 246 layers, 7.66155e+07 parameters, 7.66155e+07 gradients

 torch.Size([20, 3, 640, 640])
0/126 Sequential - [20, 32, 640, 640]
1/126 Sequential - [20, 64, 320, 320]
2/126 Sequential - [20, 32, 320, 320]
3/126 Sequential - [20, 64, 320, 320]
4/126 WeightedFeatureFusion - [20, 64, 320, 320]  >> layer -3 [20, 64, 320, 320]
5/126 Sequential - [20, 128, 160, 160]
6/126 Sequential - [20, 64, 160, 160]
7/126 Sequential - [20, 128, 160, 160]
8/126 WeightedFeatureFusion - [20, 128, 160, 160]  >> layer -3 [20, 128, 160, 160]
9/126 Sequential - [20, 64, 160, 160]
10/126 Sequential - [20, 128, 160, 160]
11/126 WeightedFeatureFusion - [20, 128, 160, 160]  >> layer -3 [20, 128, 160, 160]
12/126 Sequential - [20, 256, 80, 80]
13/126 Sequential - [20, 128, 80, 80]
14/126 Sequential - [20, 256, 80, 80]
15/126 WeightedFeatureFusion - [20, 256, 80, 80]  >> layer -3 [20, 256, 80, 80]
16/126 Sequential - [20, 128, 80, 80]
17/126 Sequential - [20, 256, 80, 80]
18/126 WeightedFeatureFusion - [20, 256, 80, 80]  >> layer -3 [20, 256, 80, 80]
19/126 Sequential - [20, 128, 80, 80]
20/126 Sequential - [20, 256, 80, 80]
21/126 WeightedFeatureFusion - [20, 256, 80, 80]  >> layer -3 [20, 256, 80, 80]
22/126 Sequential - [20, 128, 80, 80]
23/126 Sequential - [20, 256, 80, 80]
24/126 WeightedFeatureFusion - [20, 256, 80, 80]  >> layer -3 [20, 256, 80, 80]
25/126 Sequential - [20, 128, 80, 80]
26/126 Sequential - [20, 256, 80, 80]
27/126 WeightedFeatureFusion - [20, 256, 80, 80]  >> layer -3 [20, 256, 80, 80]
28/126 Sequential - [20, 128, 80, 80]
29/126 Sequential - [20, 256, 80, 80]
30/126 WeightedFeatureFusion - [20, 256, 80, 80]  >> layer -3 [20, 256, 80, 80]
31/126 Sequential - [20, 128, 80, 80]
32/126 Sequential - [20, 256, 80, 80]
33/126 WeightedFeatureFusion - [20, 256, 80, 80]  >> layer -3 [20, 256, 80, 80]
34/126 Sequential - [20, 128, 80, 80]
35/126 Sequential - [20, 256, 80, 80]
36/126 WeightedFeatureFusion - [20, 256, 80, 80]  >> layer -3 [20, 256, 80, 80]
37/126 Sequential - [20, 512, 40, 40]
38/126 Sequential - [20, 256, 40, 40]
39/126 Sequential - [20, 512, 40, 40]
40/126 WeightedFeatureFusion - [20, 512, 40, 40]  >> layer -3 [20, 512, 40, 40]
41/126 Sequential - [20, 256, 40, 40]
42/126 Sequential - [20, 512, 40, 40]
43/126 WeightedFeatureFusion - [20, 512, 40, 40]  >> layer -3 [20, 512, 40, 40]
44/126 Sequential - [20, 256, 40, 40]
45/126 Sequential - [20, 512, 40, 40]
46/126 WeightedFeatureFusion - [20, 512, 40, 40]  >> layer -3 [20, 512, 40, 40]
47/126 Sequential - [20, 256, 40, 40]
48/126 Sequential - [20, 512, 40, 40]
49/126 WeightedFeatureFusion - [20, 512, 40, 40]  >> layer -3 [20, 512, 40, 40]
50/126 Sequential - [20, 256, 40, 40]
51/126 Sequential - [20, 512, 40, 40]
52/126 WeightedFeatureFusion - [20, 512, 40, 40]  >> layer -3 [20, 512, 40, 40]
53/126 Sequential - [20, 256, 40, 40]
54/126 Sequential - [20, 512, 40, 40]
55/126 WeightedFeatureFusion - [20, 512, 40, 40]  >> layer -3 [20, 512, 40, 40]
56/126 Sequential - [20, 256, 40, 40]
57/126 Sequential - [20, 512, 40, 40]
58/126 WeightedFeatureFusion - [20, 512, 40, 40]  >> layer -3 [20, 512, 40, 40]
59/126 Sequential - [20, 256, 40, 40]
60/126 Sequential - [20, 512, 40, 40]
61/126 WeightedFeatureFusion - [20, 512, 40, 40]  >> layer -3 [20, 512, 40, 40]
62/126 Sequential - [20, 1024, 20, 20]
63/126 Sequential - [20, 512, 20, 20]
64/126 Sequential - [20, 1024, 20, 20]
65/126 WeightedFeatureFusion - [20, 1024, 20, 20]  >> layer -3 [20, 1024, 20, 20]
66/126 Sequential - [20, 512, 20, 20]
67/126 Sequential - [20, 1024, 20, 20]
68/126 WeightedFeatureFusion - [20, 1024, 20, 20]  >> layer -3 [20, 1024, 20, 20]
69/126 Sequential - [20, 512, 20, 20]
70/126 Sequential - [20, 1024, 20, 20]
71/126 WeightedFeatureFusion - [20, 1024, 20, 20]  >> layer -3 [20, 1024, 20, 20]
72/126 Sequential - [20, 512, 20, 20]
73/126 Sequential - [20, 1024, 20, 20]
74/126 WeightedFeatureFusion - [20, 1024, 20, 20]  >> layer -3 [20, 1024, 20, 20]
75/126 Sequential - [20, 512, 20, 20]
76/126 Sequential - [20, 1024, 20, 20]
77/126 Sequential - [20, 512, 20, 20]
78/126 MaxPool2d - [20, 512, 20, 20]
79/126 FeatureConcat - [20, 512, 20, 20]  >> layer -2 [20, 512, 20, 20]
80/126 MaxPool2d - [20, 512, 20, 20]
81/126 FeatureConcat - [20, 512, 20, 20]  >> layer -4 [20, 512, 20, 20]
82/126 MaxPool2d - [20, 512, 20, 20]
83/126 FeatureConcat - [20, 2048, 20, 20]  >> layer -1 [20, 512, 20, 20] + layer -3 [20, 512, 20, 20] + layer -5 [20, 512, 20, 20] + layer -6 [20, 512, 20, 20]
84/126 Sequential - [20, 512, 20, 20]
85/126 Sequential - [20, 1024, 20, 20]
86/126 Sequential - [20, 512, 20, 20]
87/126 FeatureConcat - [20, 2560, 20, 20]  >> layer -1 [20, 512, 20, 20] + layer 83 [20, 512, 20, 20]
88/126 Sequential - [20, 1024, 20, 20]
89/126 Sequential - [20, 1024, 20, 20]
90/126 Sequential - [20, 512, 20, 20]
91/126 Sequential - [20, 1024, 20, 20]
92/126 Sequential - [20, 42, 20, 20]
93/126 YOLOLayer - [20, 42, 20, 20]
94/126 FeatureConcat - [20, 512, 20, 20]  >> layer -4 [20, 42, 20, 20]
95/126 Sequential - [20, 256, 20, 20]
96/126 Upsample - [20, 256, 40, 40]
97/126 FeatureConcat - [20, 768, 40, 40]  >> layer -1 [20, 256, 40, 40] + layer 61 [20, 256, 40, 40]
98/126 Sequential - [20, 256, 40, 40]
99/126 Sequential - [20, 512, 40, 40]
100/126 Sequential - [20, 256, 40, 40]
101/126 FeatureConcat - [20, 256, 80, 80]  >> layer -65 [20, 256, 40, 40]
102/126 Sequential - [20, 256, 40, 40]
103/126 FeatureConcat - [20, 512, 40, 40]  >> layer -1 [20, 256, 40, 40] + layer 100 [20, 256, 40, 40]
104/126 Sequential - [20, 256, 40, 40]
105/126 Sequential - [20, 512, 40, 40]
106/126 Sequential - [20, 256, 40, 40]
107/126 Sequential - [20, 512, 40, 40]
108/126 Sequential - [20, 42, 40, 40]
109/126 YOLOLayer - [20, 42, 40, 40]
110/126 FeatureConcat - [20, 256, 40, 40]  >> layer -4 [20, 42, 40, 40]
111/126 Sequential - [20, 128, 40, 40]
112/126 Upsample - [20, 128, 80, 80]
113/126 FeatureConcat - [20, 384, 80, 80]  >> layer -1 [20, 128, 80, 80] + layer 36 [20, 128, 80, 80]
114/126 Sequential - [20, 128, 80, 80]
115/126 Sequential - [20, 256, 80, 80]
116/126 Sequential - [20, 128, 80, 80]
117/126 FeatureConcat - [20, 128, 160, 160]  >> layer -106 [20, 128, 80, 80]
118/126 Sequential - [20, 256, 80, 80]
119/126 FeatureConcat - [20, 384, 80, 80]  >> layer -1 [20, 256, 80, 80] + layer 116 [20, 256, 80, 80]
120/126 Sequential - [20, 256, 80, 80]
121/126 Sequential - [20, 128, 80, 80]
122/126 Sequential - [20, 256, 80, 80]
123/126 Sequential - [20, 256, 80, 80]
124/126 Sequential - [20, 42, 80, 80]
125/126 YOLOLayer - [20, 42, 80, 80]

